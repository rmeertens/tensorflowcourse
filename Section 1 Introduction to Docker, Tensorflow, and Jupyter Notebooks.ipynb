{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset Driven Approach to Building Neural Networks with TensorFlow \n",
    "\n",
    "Welcome to the first section fo the course \"The Dataset Driven Approach to Building Neural Networks with Tensorflow\". In this section you are going to learn: \n",
    "- That deep learning both a science and an art\n",
    "- Why we use Docker, and how to get access to all the code\n",
    "- How to use a Jupyter notebook\n",
    "- What Tensorflow is and how you work with it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 1: solving public datasets and your own sets: is deep learning a science or an art? \n",
    "People often discuss whether being good at deep learning requires a lot of knowledge (like a scientist), or requires a lot of practice (like an artist). With these questions the answer always is: you need to have a combination of both. Only solving a lot of datasets will give you the intuition to build neural networks for new datasets. However, if you want to solve your problems better than anyone else, you will need to know exactly why you apply certain techniques in neural networks. \n",
    "\n",
    "In a [scientific paper from 1994](http://dl.acm.org/citation.cfm?id=181522) scientists already see this problem coming. Now deep learning is very popular many people want to use it on their own datasets. Many will achieve results that are satisfactory, but only really understanding the problem allows you to solve the problem. \n",
    "\n",
    "In this course you will learn to be a network artist and a network scientist at the same time.  practicing on many datasets will give you a good intuition in what techniques you can apply for certain problems. We discuss what techniques do, and immediately use this to solve datasets. After you are done with the course you can revisit the first problems you faced and use the knowledge you gained to solve the first few problems even better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Video 2: Why we use Docker, and installation instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Often when you follow a course online you need to install many programs before you can finally start programming your coursework. For this course you only need to install one program: **Docker**. \n",
    "\n",
    "Docker is a tool which allows you to run an isolated operating system on your computer. It's like you are running a pc, on your pc. You can run a second Windows in Windows, or an Ubuntu (Linux) server under Windows. \n",
    "\n",
    "For this course I made a **Docker image** that contains all dependencys you normally would have to install. This means everyone who joins has the same Python version, the same version of Tensorflow, and no problems with libraries. \n",
    "\n",
    "Unfortunately, you still need to get one program running before you can start: Docker itself. \n",
    "\n",
    "### Installation\n",
    "The best way to install Docker is by looking at this webpage: https://docs.docker.com/engine/installation/#supported-platforms\n",
    "If you are on Windows 7 you need to install [Docker Toolbox](https://docs.docker.com/toolbox/toolbox_install_windows/). \n",
    "\n",
    "This video by Elton Stoneman is a great tutorial on how to install Docker on Windows: https://www.youtube.com/watch?v=S7NVloq0EBc. \n",
    "For fellow OSX users I took the following screenshots to see what links you have to follow to install Docker. \n",
    "\n",
    "![find desktop](illustrations/section1/finddesktop.png)\n",
    "![click stable](illustrations/section1/clickstable.png)\n",
    "![drag docker](illustrations/section1/dragdocker.png)\n",
    "\n",
    "Make sure you launch Docker and it runs as process in the background. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 3: where to find the Jupyter notebook and code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once you install Docker getting started is easy. Open a terminal and verify that typing docker works: \n",
    "\n",
    "> `docker`\n",
    "\n",
    "Download the code from TODO PACKT URL HERE!\n",
    "In the folder you downloaded create a folder called \"datasets\". We will fill this folder during the course \n",
    "\n",
    "In your terminal navigate to the folder you downloaded from Packt (using the `cd` command). \n",
    "Run the following command: \n",
    "> `docker-machine build` \n",
    "\n",
    "This command will take a while, as you download an image with an operating system, Tensorflow, and several libraries you need for the course. Although it might be a little bit of a hassle now I found that working with Docker for courses like this significantly improves the experience of people who can follow the course. Installing just one program turns out to be way better than installing the 5 libraries you need during the course. \n",
    "\n",
    "Once this command is done you run the following command: \n",
    "> `docker-machine up`\n",
    "\n",
    "If all went well you should be able to navigate to `localhost:8888` and see the following screen:\n",
    "\n",
    "\n",
    "Now navigate to this folder in your terminal, and run\n",
    "> `docker run rmeertens/datasetdriventensorflow` \n",
    "\n",
    "Here should be something about mounting a volume to keep your progress, and we have to load the datasets from a volume as I don't want to include these.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 4: Understanding Tensorflow\n",
    "\n",
    "In the previous video we saw how to work with a Jupyter notebook. Hopefully you succeeded, and you managed to open a notebook. This is the fourth video, where we are going to use the Jupyter notebook you downloaded to understand **Tensorflow**. \n",
    "\n",
    "In this video we:\n",
    "- go over the definition of Tensorflow\n",
    "- show how simple mathematical operations work in Tensorflow\n",
    "- use placeholders to bring values outside our Tensorflow graph into the graph\n",
    "- are going to chain multiple operations together\n",
    "- are going to inspect our graph\n",
    "\n",
    "### The definition of Tensorflow\n",
    "\n",
    "According to https://www.tensorflow.org/\n",
    "> TensorFlowâ„¢ is an open source software library for numerical computation using data flow graphs.\n",
    "\n",
    "As you are following this course you probably don't know what they mean with this. Don't worry, we will figure it out in this section!\n",
    "\n",
    "> Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them. \n",
    "\n",
    "Wow, this is really abstract. Let's not think about this sentence for now. \n",
    "\n",
    "> The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API.\n",
    "\n",
    "Oeh, that sounds like something we want to use! I personally love deep learning and neural networks, and having them on my computer, a server, and a mobile phone sounds pretty good. \n",
    "\n",
    "Let's dive into the data flow graphs Tensorflow is well known for. Normally in Python everything you type with variables is evaluated immediately. Take a look at this example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "a = 1.0\n",
    "b = 2.0\n",
    "c = a + b\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow works a little different. You first define the variables and operations in a graph. You then 'compile' and build up this graph, and evaluate it in a session you defined:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bcec29c101be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# sess = tf.Session()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Evaluate the tensor `c`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Example from here: https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "# Build a graph.\n",
    "a = tf.constant(1.0)\n",
    "b = tf.constant(2.0)\n",
    "c = a + b\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Evaluate the tensor `c`.\n",
    "print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the variable C is an \"operation\" with two constants as input: a and b. In an image this looks like this: \n",
    "![graph def](illustrations/firstmul.png)\n",
    "\n",
    "Now let's see what the sess.run function actually does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Python is pretty good for mathematical operations, especially if you import the Numpy library: a [package for scientific computing](http://www.numpy.org/). Let's take a look at how you add two random matrices ([arrays with numbers](https://en.wikipedia.org/wiki/Matrix_(mathematics) ))together with numpy: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "matrix_a = np.random.rand(2,3)\n",
    "matrix_b = np.random.rand(2,3)\n",
    "matrix_c = matrix_a + matrix_b\n",
    "print(matrix_a)\n",
    "print(matrix_b)\n",
    "print(matrix_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tensorflow you can define these variables as variables in your computation graph. You can select how they are initialised, and the operations you want to do on this graph: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_a = tf.Variable(tf.random_uniform([2, 3]), name=\"matrix_a\")\n",
    "matrix_b = tf.Variable(tf.random_uniform([2, 3]), name=\"matrix_b\")\n",
    "matrix_c = matrix_a + matrix_b\n",
    "\n",
    "print(matrix_a)\n",
    "print(matrix_b)\n",
    "print(matrix_c)\n",
    "try:\n",
    "    print(sess.run(matrix_a))\n",
    "    print(sess.run(matrix_b))\n",
    "    print(sess.run(matrix_c))\n",
    "except Exception as e:\n",
    "    print(\"EXCEPTION!\")\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welp: looks like Tensorflow does not like what we are doing. In this case we specified that we wanted to initialise our variables with random values. To do that you have to **initialise** the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer\n",
    "print(init)\n",
    "# sess = tf.Session() # https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "sess.run(init)\n",
    "print(sess.run(matrix_a))\n",
    "print(sess.run(matrix_b))\n",
    "print(sess.run(matrix_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It works. The graph that we defined now looks like this: \n",
    "![mat add](illustrations/matadd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "Now you know how to play with static data we are going to make it a little bit more interesting, and start working with placeholders. \n",
    "\n",
    "Let's say we want to add one to each element in the following matrix: \n",
    "\n",
    "\\begin{matrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6\n",
    "\\end{matrix}\n",
    "\n",
    "Here is how we do this with numpy: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_matrix = np.array([[1,2],[3,4],[5,6]])\n",
    "to_add_matrix = np.ones([3,2])\n",
    "result_matrix = our_matrix + to_add_matrix\n",
    "print(our_matrix)\n",
    "print(to_add_matrix)\n",
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with Tensorflow this would look like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "input_shape = [3,2]\n",
    "inputplaceholder = tf.placeholder(dtype=tf.int32, shape=input_shape, name=\"input_placeholder\") # https://www.tensorflow.org/api_docs/python/tf/placeholder\n",
    "print(inputplaceholder)\n",
    "toadd = tf.ones(input_shape) # https://www.tensorflow.org/api_guides/python/constant_op\n",
    "try:\n",
    "    together = inputplaceholder + toadd\n",
    "    print(together)\n",
    "except Exception as e:\n",
    "    print(\"ERROR!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welp, an error occured. It looks like the `tf.ones` function expects a `dtype` variable. Let's define that both variables contain integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputplaceholder = tf.placeholder(dtype=tf.int32, shape=input_shape, name=\"input_placeholder\")\n",
    "toadd = tf.ones(input_shape,dtype=tf.int32)\n",
    "together = inputplaceholder + toadd\n",
    "print(together)\n",
    "\n",
    "init = tf.global_variables_initializer() # https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer\n",
    "# sess = tf.Session() # https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "sess.run(init)\n",
    "result = sess.run(together, feed_dict={inputplaceholder: our_matrix})\n",
    "print('-'*10)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "According to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/dtypes.py\n",
    "The following `DType` objects are defined:\n",
    "  * `tf.float16`: 16-bit half-precision floating-point.\n",
    "  * `tf.float32`: 32-bit single-precision floating-point.\n",
    "  * `tf.float64`: 64-bit double-precision floating-point.\n",
    "  * `tf.bfloat16`: 16-bit truncated floating-point.\n",
    "  * `tf.complex64`: 64-bit single-precision complex.\n",
    "  * `tf.complex128`: 128-bit double-precision complex.\n",
    "  * `tf.int8`: 8-bit signed integer.\n",
    "  * `tf.uint8`: 8-bit unsigned integer.\n",
    "  * `tf.uint16`: 16-bit unsigned integer.\n",
    "  * `tf.int16`: 16-bit signed integer.\n",
    "  * `tf.int32`: 32-bit signed integer.\n",
    "  * `tf.int64`: 64-bit signed integer.\n",
    "  * `tf.bool`: Boolean.\n",
    "  * `tf.string`: String.\n",
    "  * `tf.qint8`: Quantized 8-bit signed integer.\n",
    "  * `tf.quint8`: Quantized 8-bit unsigned integer.\n",
    "  * `tf.qint16`: Quantized 16-bit signed integer.\n",
    "  * `tf.quint16`: Quantized 16-bit unsigned integer.\n",
    "  * `tf.qint32`: Quantized 32-bit signed integer.\n",
    "  * `tf.resource`: Handle to a mutable resource.\n",
    "  * `tf.variant`: Values of arbitrary types.\n",
    "\n",
    "Try to keep these datatypes in mind when you are developing your own application!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining operations\n",
    "Right now we only made very simple graphs with only one operation. Let's say we want to make a more interesting graph where we apply several operations. To make the graph more clear I will give the operations a name this time. This looks like this in Tensorflow:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.add?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_matrix = np.array([[1,2],[3,4],[5,6]])\n",
    "print(our_matrix.shape)\n",
    "inputplaceholder = tf.placeholder(dtype=tf.int32, shape=our_matrix.shape, name=\"input_placeholder\")\n",
    "toadd1 = tf.ones(input_shape,dtype=tf.int32, name='first_ones')\n",
    "toadd2 = tf.ones(input_shape,dtype=tf.int32, name='second_ones')\n",
    "together1 = tf.add(inputplaceholder, toadd1, name='first_addition')\n",
    "together2 = tf.add(together1, toadd2, name='second_addition')\n",
    "together3 = tf.add(together2, toadd1, name='last_addition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the following graph:\n",
    "![bigger graph](illustrations/biggergraph.png)\n",
    "If we take a sessions and evaluate the result of the last operation while we feed a placeholder every operation to achieve this result is executed in the background: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer\n",
    "# sess = tf.Session() # https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "sess.run(init)\n",
    "\n",
    "result = sess.run(together3, feed_dict={inputplaceholder: our_matrix})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing what's in your graph\n",
    "Sometimes it can be useful to know what kind of operations are in your graph. You can do this with the following call: \n",
    "`print([op.name for op in tf.get_default_graph().get_operations()])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print([op.name for op in tf.get_default_graph().get_operations()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sometimes you want to remove everything in your graph and start all over again. You can do this with this piece of code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion section 1\n",
    "In this section we talked about the approach we take during this course to learn about neural networks and Tensorflow. We installed Docker and loaded the Jupyter notebook in it. \n",
    "\n",
    "In this video you saw that Tensorflow works a bit different than what you normally expect if you use Python. It takes a bit of time and practice to get used to defining graphs, but during this course we will do it very often, so you will become good at it!\n",
    "\n",
    "In the next section we are going to solve our first dataset: one in which we are going to classify three types of flowers with our first neural network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "\n",
    "show_graph(tf.get_default_graph().as_graph_def())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
