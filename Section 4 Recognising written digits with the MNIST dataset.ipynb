{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Recognising written digits with the MNIST dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Video 1: downloading the data, and visualising it\n",
    "The MNIST database (Modified National Institute of Standards and Technology database) consists of labeled images of written digits. Each image is a grayscale image which is normalized to fit into a 20x20 pixel bounding box, and anti-aliased. The MNIST database is a derivative of the NIST dataset, and contains 60,000 training images and 10,000 testing images\n",
    "\n",
    "The MNIST dataset is used very often in projects, as it is a great practical example to test your network on. New novel network architectures often show how well they perform on the MNIST dataset. Even if your new network architecture does not perform better, it's often easy to show interesting features using the MNIST dataset. As it's used very often, loading the MNIST dataset is included in your installation of Tensorflow. \n",
    "\n",
    "Execute the following code will either load the data, and if it's your first time loading the data it will download the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"datasets/MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising MNIST\n",
    "Just like the previous sections I think it's important to know how our data is represented. In this case we see that we are dealing with a `Datasets` object, and that we can get a batch of images and labels from this object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = mnist.train.next_batch(5)\n",
    "print(len(images[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the images\n",
    "One important thing to know is that one digit is a long array. In this case we can use NumPy to reshape our data to visualise it with Matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "images, labels = mnist.train.next_batch(10)\n",
    "for image, label in zip(images, labels):\n",
    "    image_reshaped = np.reshape(image, (28,28))\n",
    "    \n",
    "    plt.imshow(image_reshaped)\n",
    "    plt.show()\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nicer visualisations and difficult data\n",
    "If you want to see all digits in a multi-dimensional space you can take a look at this [blogpost](http://www.pinchofintelligence.com/simple-introduction-to-tensorboard-embedding-visualisation/) I made about using Tensorboard and the MNIST digits. Another interesting link you can try is the [notmnist dataset](http://yaroslavvb.blogspot.nl/2011/09/notmnist-dataset.html) which consists of alphabetical characters in several funky fonts:\n",
    "![not mnist](http://yaroslavvb.com/upload/notMNIST/nmn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 2: Dense layer approach\n",
    "In the previous videos we only used dense layers to make predictions. Let's do this again, but this time for image recognition and see what score we get. \n",
    "Note that we keep using the mean squared error as loss function, and the gradient descent optimizer. We will quickly introduce a better function to replace it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.05\n",
    "ACTIVATION_FUNCTION = tf.nn.relu\n",
    "INPUT_UNITS = 28*28\n",
    "OUTPUT_UNITS = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x_placeholder = tf.placeholder(tf.float32, [None, INPUT_UNITS], name=\"x_placeholder\")\n",
    "y_placeholder = tf.placeholder(tf.float32, [None, OUTPUT_UNITS], name=\"y_placeholder\")\n",
    "\n",
    "hiddenlayer = tf.layers.dense(inputs=x_placeholder, units=400, activation=ACTIVATION_FUNCTION, name=\"hidden_layer\")\n",
    "predicted_class = tf.layers.dense(inputs=hiddenlayer, units=OUTPUT_UNITS, activation=ACTIVATION_FUNCTION, name=\"prediction\")\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_placeholder,predicted_class)\n",
    "optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer\n",
    "sess = tf.InteractiveSession() # https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "ITERATIONS = 1000\n",
    "losses = list()\n",
    "for _ in range(ITERATIONS):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "    opt_res, current_loss = sess.run([optimizer, loss], feed_dict={x_placeholder: batch_xs, y_placeholder: batch_ys})\n",
    "    losses.append(current_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(dataset, inputtensor, outputtensor, session, test_size=1000, batch_size=32):\n",
    "    correct_predictions = 0\n",
    "    total_tested = 0\n",
    "    for _ in range(int(test_size/batch_size)):\n",
    "        total_tested += batch_size\n",
    "        batch_xs, batch_ys = dataset.next_batch(batch_size)\n",
    "        predicted_chars = session.run(outputtensor, feed_dict={inputtensor: batch_xs})\n",
    "        for truechar, predictedchar in zip(batch_ys, predicted_chars):\n",
    "            if np.argmax(truechar) == np.argmax(predictedchar): # https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "                correct_predictions += 1\n",
    "    return correct_predictions/total_tested\n",
    "\n",
    "accuracy = get_accuracy(mnist.test, x_placeholder, predicted_class, sess)\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to state of the art\n",
    "Although what we have right now seems pretty good, it's important to take a look at what the state of the art is doing: http://rodrigob.github.io/are_we_there_yet/build/\n",
    "\n",
    "As you can see we should not be happy with our results, and continue learning to improve our network. \n",
    "![mnist results](illustrations/mnistresults.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 3: convolution and max-pooling layers\n",
    "\n",
    "![image](illustrations/six_three.png)\n",
    "Imagine you are trying to recognize the center image above. You will probably see that this is a six, and the two images next to it are also sixes... For our neural network we made above these are completely different inputs!\n",
    "What you have to know about the human brain is that there are multiple layers of vision. The \"lower\" layers recognise simple features, like lines. Higher layers take these lower features as input and make higher level features out of it. \n",
    "\n",
    "Neural networks can learn this as well! A big reason neural networks are so popular nowadays is the **convolutional layer**. A convolutional layer is a trainable **feature detector**. It activates when it detects a certain pattern. We slide multiple feature detectors over the image and record the result in a new layer. \n",
    "\n",
    "To understand this: let's start with a MNIST image:\n",
    "\n",
    "![image](illustrations/six1.png)\n",
    "\n",
    "There are some features we are probably interested in, like horizontal or vertical lines: \n",
    "\n",
    "![image](illustrations/activations_first_conv_layer.png)\n",
    "\n",
    "\n",
    "In our next layer we create ** Feature layers ** by **convolving ** a block with ** filters ** over our image. Note that in our neural network we don't define these filters ourselves, the network has to learn them itself. After this **convolution** layer we end up with a new matrix. Instead of the R,G,B dimension we would have in a colour image, we have dimensions that have the activation to a certain filter...\n",
    "\n",
    "![image](illustrations/Convsmalltomany.jpg)\n",
    "\n",
    "What you need to know is that you can represent these weights as a block: one set of weights is `[width, height, in_dimension, out_dimension]`. It is as if you make a small neural network that takes part of your image as input, and gives X features as output. Luckily we don't have to define these weights and computations ourselves. To save time and make easier to read code we will use the `tf.layers.conv2d` function. \n",
    "\n",
    "This function slides a network over the image, and puts the result in a feature map. Here is a visualisation of what roughly happens:\n",
    "![image](illustrations/Convolutiondrawing.jpg)\n",
    "\n",
    "There are some terms you need to know. If you look at the signature of the `tf.layers.conv2d` function you will see that it takes the following arguments:\n",
    "\n",
    "#### Kernel size\n",
    "The kernel size is the width and height of a single filter. Often a kernel size of 3x3 or 5x5 is chosen for classification problems. The larger the filter the more information it takes in, but it also makes your program slower and it generalises less. \n",
    "![image](illustrations/kernelsize.jpg)\n",
    "\n",
    "Note that you can even take a 1x1 convolution. In that case you are simply doing a dimensionality reduction: you try to train a neural network that can take X features (for example: 64), and represent them in Y features (for example: 32), preferably without losing a lot of information. \n",
    "\n",
    "#### Padding\n",
    "Let's say your kernel is 3x3 and your image is 5x5: there are two ways you can convolve over this image:\n",
    "\n",
    "##### Padding: valid\n",
    "You convolve over the parts that are actually visible to the detector. As output you get a feature map with a smaller width and height (in our example: result would be 4x4), because you can't slide over the edges:\n",
    "![image](illustrations/valid.jpg)\n",
    "\n",
    "##### Padding: same\n",
    "You can also choose to \"pad\" the input with zeroes around the edges. This way you get an activation for the edges, although it's a bit distorted thanks to the padding. The output of your convolution is a feature map with the SAME width and height as your input convolution map. In our example, the width and height of the output would be 4x4. \n",
    "\n",
    "![image](illustrations/same.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Strides\n",
    "You can look at every part of the image by sliding your detector over the image and shifting 1 pixel in the x direction and/or 1 pixel in the y direction. You could also choose to skip pixels, this would still give you an activation at many parts of the image, but results in a smaller output. Below I show the output for two possible strides:\n",
    "\n",
    "![image](illustrations/Strides.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Pooling\n",
    "The convolution layer provides a lot of information. It's also an operation that creates very big data structures. You can reduce the output of your convolutional layers by taking larger strides, but this way you might miss a very important feature (you skip over it). Pooling tries to solve this problem: on many points on the feature map you take combine activations in the neighbourhood.\n",
    "\n",
    "There are two popular pooling methods: max pooling and average pooling. \n",
    "\n",
    "#### Max pooling\n",
    "In max pooling we select the \"pixels\" with the highest activation in every group. Often this grouping is done in a 2x2 grid, and results in one number. This means that your data after a pooling operation is 4x smaller than before!\n",
    "\n",
    "![max pooling](https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png)\n",
    "\n",
    "We can use the Tensorflow layers function to perform our max pooling operation. If you look at the [documentation](https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d) you see that it requires some arguments you hopefully are familiar with right now:\n",
    "- Pool size: this is the same idea as the kernel size in convolution\n",
    "- Strides: the same as kernel size in convolution.\n",
    "\n",
    "We will use a pool size of (2,2) and a stride of (2,2). This results in the same effect as you see in the image above. \n",
    "\n",
    "#### Average pooling\n",
    "Instead of taxing the maximum value you take the average value of the values you are pooling. We are not using this \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it in code! Convolution and max pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_placeholder = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x_placeholder, [-1, 28, 28, 1])\n",
    "FIRST_LAYER_KERNEL_SIZE = 5\n",
    "SECOND_LAYER_KERNEL_SIZE = 3\n",
    "conv_layer1 = tf.layers.conv2d(x_image, \n",
    "                               32, \n",
    "                               (FIRST_LAYER_KERNEL_SIZE,FIRST_LAYER_KERNEL_SIZE), \n",
    "                               activation=tf.nn.relu, \n",
    "                               padding='same')\n",
    "pool_layer1 = tf.layers.max_pooling2d(conv_layer1,(2,2),(2,2),padding='SAME')\n",
    "\n",
    "conv_layer2 = tf.layers.conv2d(pool_layer1, \n",
    "                               64, \n",
    "                               (SECOND_LAYER_KERNEL_SIZE,SECOND_LAYER_KERNEL_SIZE), \n",
    "                               activation = tf.nn.relu, \n",
    "                               padding='same')\n",
    "pool_layer2 = tf.layers.max_pooling2d(conv_layer2,(2,2),(2,2),padding='SAME')\n",
    "\n",
    "flattened = tf.contrib.layers.flatten(pool_layer2)\n",
    "hidden_fully_connected_layer = tf.layers.dense(inputs=flattened, units=1024, activation=tf.nn.relu)\n",
    "y_conv = tf.layers.dense(inputs=hidden_fully_connected_layer, units=10, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(y_placeholder, y_conv)\n",
    "train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "ITERATIONS = 1000\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "losses = list()\n",
    "for iteration in range(ITERATIONS):\n",
    "    batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    _, l = sess.run([train_step, loss], feed_dict={x_placeholder: batch[0], y_placeholder: batch[1]})\n",
    "    losses.append(l)\n",
    "    \n",
    "    ## Added: every 100 steps print the accuracy!\n",
    "    if iteration % 100 == 0:\n",
    "        accuracy = get_accuracy(mnist.test, x_placeholder, y_conv, sess, test_size=100)\n",
    "        print(\"Iteration %d, loss: %f, accuracy: %f\" % (iteration, l, accuracy))\n",
    "        \n",
    "accuracy = get_accuracy(mnist.test, x_placeholder, y_conv, sess, test_size=10000)\n",
    "print(\"Final performance: accuracy: %f\" % (accuracy))\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Putting convolutional operations in your neural network\n",
    "We now saw how we could improve our performance on the MNIST task with convolutional and pooling layers! \n",
    "\n",
    "Depending on the task you are trying to solve. In classification problems you often:\n",
    "- Take the data as input\n",
    "- Represent it as an image with shape [batch_size, width, height, dimensions]\n",
    "- Do a convolution with activation function\n",
    "- Do a pooling layer\n",
    "- Repeat convolution + pooling layers for as long as you want\n",
    "- Reshape it \n",
    "- Add (some) dense layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 4: from activations to probabilities: the softmax function\n",
    "Note that if we currently get the output of our MNIST detection network we get an activation. Often people on StackOverflow ask how they get a \"certainty\", or \"probability\" estimate for each class. \n",
    "\n",
    "A function that provides a probability distribution over our classes is the [**softmax function**](https://en.wikipedia.org/wiki/Softmax_function). It takes the activations as input, and for each activation it divides $e^{activation}$ by the sum of each $e^{activation}$. It thus looks like this: \n",
    "\n",
    "$softmax(activation_j) = \\frac{e^{activation_j}}{\\sum_i e^{activation_i}}$\n",
    "\n",
    "Adding the softmax function to our graph is easy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "softmax_output = tf.nn.softmax(y_conv)\n",
    "smoutput, a_output = sess.run([softmax_output, y_conv], feed_dict={x_placeholder: batch[0]})\n",
    "print(\"Activation output: \" + str( a_output[0]))\n",
    "print(\"Softmax output: \" + str(smoutput[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of the Softmax function\n",
    "Some important properties of the softmax function you might want to remember are:\n",
    "- Resulting values sum up to 1\n",
    "- Weighting of input is nonlinear: large inputs get more weight than small inputs!\n",
    "\n",
    "Let's take a look at this last property: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(inputs):\n",
    "    e_x = np.exp(inputs - np.max(inputs))\n",
    "    return e_x / e_x.sum()\n",
    "def linear(inputs):\n",
    "    return inputs / inputs.sum()\n",
    "\n",
    "example_activation = np.array([1,2,3,4,1,2,3])\n",
    "\n",
    "print(\"Softmax: \" + str(softmax(example_activation)))\n",
    "print(\"Linear: \" + str(linear(example_activation)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 5: optimization and loss functions\n",
    "Right now we used the mean squared error to determine our loss, and the gradient descent optimization function. Let's first discuss some alternatives to the mean squared error loss function:\n",
    "\n",
    "### Loss functions\n",
    "Mean squared error not only gives a penalty for not being certain about the class you want, it also gives a penalty for being \"confused\" about another class. For many classification problems it turns out that it's a good idea to run a softmax over the outputs, and then only give a penalty for the error in the expected class. \n",
    "\n",
    "There are more loss functions in Tensorflow I won't talk about in these videos. This list [can be found here.](https://www.tensorflow.org/api_docs/python/tf/losses) A short article about them can be found on [this site](https://www.tensorflow.org/api_guides/python/contrib.losses)\n",
    "\n",
    "A great article going deeper into why you want to use softmax cross entropy loss for classification problems can be [found here](https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/). \n",
    "\n",
    "In the future, remember that if you are dealing with a classification problem it's a good idea to use the cross entropy error (note: perhaps you can revisit the iris dataset in section 2!). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization functions\n",
    "Just like picking a better loss function there are some other optimization functions that can be better than the gradient descent function we used in the previous videos. To understand these optimization function we need to look at the representation of our learning landscape again: \n",
    "\n",
    "\n",
    "There are some great articles on optimization algorithms that I can really recommend. This one has a \"what should I use approach: https://medium.com/towards-data-science/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f\n",
    "While this article has a more mathematical approach: http://ruder.io/optimizing-gradient-descent/\n",
    "\n",
    "#### Momentum optimization\n",
    "For the momentum optimization function you have to imagine that every optimization step we move in the direction of our loss. If we have a simple function this means we find the minimum of our function (provided our learning rate is good). If there are local minimum we could get stuck here. \n",
    "\n",
    "An optimization function that tries to deal with local minimas is the **momentum function**. Instead of taking the error and moving in that direction you add weigh this with a momentum variable to adjust the direction you were moving in. \n",
    "\n",
    "Compare it to a rolling ball: if it is rolling down with a certain speed and encounters a small hill it can just roll over it. \n",
    "\n",
    "![image](illustrations/momentumlearning.jpg)\n",
    "\n",
    "#### ADAM optimisation \n",
    "The ADAM optimization algorithm takes a totally different approach. It uses two important characteristics: \n",
    "- We give a learning rate parameter to each weight, and adjust this weight every update. This improves performance on problems with \"sparse\" gradients, like natural language and computer vision problems.\n",
    "- These parameters are adapted based on the average of recent magnitudes of the gradients for that weight. This is good for \"noisy\" data. \n",
    "\n",
    "#### Choosing your optimizer\n",
    "\n",
    "Choosing your optimizer can be a difficult task. Just like choosing the right learning rate can be a big difference (like we saw in section 3), choosing the right optimizer can also give you several percentages increase in performance. In this video we only change the optimizer to the Adam Optimizer, but try out some others!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_placeholder, logits=y_conv)\n",
    "loss = tf.reduce_sum(cross_entropy)\n",
    "train_step_cross_entropy = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "losses = list()\n",
    "for iteration in range(ITERATIONS):\n",
    "    batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    _, l = sess.run([train_step_cross_entropy, loss], \n",
    "                    feed_dict={x_placeholder: batch[0], \n",
    "                               y_placeholder: batch[1]})\n",
    "    losses.append(l)\n",
    "    \n",
    "    ## Added: every 100 steps print the accuracy!\n",
    "    if iteration % 100 == 0:\n",
    "        accuracy = get_accuracy(mnist.test, x_placeholder, y_conv, sess, test_size=100)\n",
    "        print(\"Iteration %d, loss: %f, accuracy: %f\" % (iteration, l, accuracy))\n",
    "        \n",
    "accuracy = get_accuracy(mnist.test, x_placeholder, y_conv, sess, test_size=10000)\n",
    "print(\"Final performance: accuracy: %f\" % (accuracy))\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "In this section we took on the challenge of recognising digits. We started with knowledge we already had (a deep neural network with dense layers), but learned that using convolution and pooling layers we got a better result. We also learned that using a different loss function and different optimization algorithm improved our accuracy with a few percent. \n",
    "\n",
    "With this knowledge we are ready for a big and difficult final project: recognize properties in human faces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END \n",
    "# END \n",
    "# END \n",
    "# END # END # END \n",
    "# END \n",
    "# END \n",
    "# END \n",
    "v\n",
    "# END \n",
    "# END \n",
    "# END \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 4: from activations to probabilities: the softmax function\n",
    "A question I find way too often on Stackoverflow is how people can go from an activation in their final layer to a probability that the network is \"correct\". Imagine the network gives you the following activation: `[0.1, 0.3, 0.9, 0.4]`. We probably want guess the network predicted the 3rd class. There are several methods to 'normalize' this outcome. A popular way to do this with neural networks is the [softmax function, or 'normalized exponential function'](https://en.wikipedia.org/wiki/Softmax_function).\n",
    "\n",
    "The softmax function is: $Softmax(vector_i) \\frac{e^{vector_i}}{\\sum_j e^{vector_j} }$\n",
    "The softmax function is a great nonregularity to add to on the final layer of our neural network. \n",
    "\n",
    "If you are wondering why in particular the softmax function is such a good function, take a look at the [following Stackoverflow answer](https://stackoverflow.com/questions/17187507/why-use-softmax-as-opposed-to-standard-normalization). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Understanding and adding convolutional layers and comparing our performance to state of the art. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.layers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x_placeholder = tf.placeholder(tf.float32, [None, INPUT_UNITS], name=\"x_placeholder\")\n",
    "y_placeholder = tf.placeholder(tf.float32, [None, OUTPUT_UNITS], name=\"y_placeholder\")\n",
    "\n",
    "\n",
    "reshaped1 = tf.reshape(x_placeholder, shape=[-1,28,28,1])\n",
    "conv1 = tf.layers.conv2d(reshaped1, 30, (5,5), strides=(2, 2), activation=tf.nn.relu)\n",
    "conv2 = tf.layers.conv2d(conv1, 30, (3,3), strides=(1, 1), activation=tf.nn.relu)\n",
    "print(conv2)\n",
    "flattened = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "hiddenlayer = tf.layers.dense(inputs=flattened, units=400, activation=ACTIVATION_FUNCTION, name=\"hidden_layer\")\n",
    "predicted_class = tf.layers.dense(inputs=hiddenlayer, units=OUTPUT_UNITS, activation=ACTIVATION_FUNCTION, name=\"prediction\")\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_placeholder, logits=predicted_class))\n",
    "adamoptimizer = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    "# sgdoptimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer\n",
    "sess = tf.Session() # https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = list()\n",
    "for _ in range(ITERATIONS):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "    opt_res, current_loss = sess.run([adamoptimizer, cross_entropy], feed_dict={x_placeholder: batch_xs, y_placeholder: batch_ys})\n",
    "    losses.append(current_loss)\n",
    "plt.plot(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracies = list()\n",
    "for _ in range(10):\n",
    "    accuracy = get_accuracy(mnist.test, x_placeholder, predicted_class, test_size=100)\n",
    "    print(accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "print(\"Accuracy: \" + str(sum(accuracies)/len(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is one thing you should know about how we go over the image with this type of network. We can either apply this filter at every point of the image. This would of course give us the best results, but would result in a very big map in the next layer. It's often good enough to apply this filter at multiple points in the image. This is called the **stride**. \n",
    "\n",
    "Another thing you need to know is that if you apply these filters on an image you could apply them only on the real part of the image. You can also say: \"I'm still applying my filter on the edges and fill the edges with something random or black\". This is called the **padding**. There are two modes for padding: \n",
    "- Valid: we don't apply our convolutional filter on the sides of our image\n",
    "- Same: we do apply our convolutional filter on the sides of the image. If we have stride 1-1 we get the same output in the next layer. \n",
    "\n",
    "Now let's apply our filter on an input image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can easily change is the activation function of our network. In [this paper]( https://arxiv.org/abs/1502.01852) authors attempt to solve a more difficult problem: imagenet. In this competition you see many images, and you have to guess what's in the image. To improve upon the state of the art they compare several activation functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My aantekeningen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "FIRST_LAYER_SIZE = 10\n",
    "h_conv1 = tf.layers.conv2d(x_image, 32, (FIRST_LAYER_SIZE,FIRST_LAYER_SIZE), activation=tf.nn.relu, padding='same')\n",
    "h_pool1 = tf.layers.max_pooling2d(h_conv1,(2,2),(2,2),padding='SAME')\n",
    "\n",
    "h_conv2 = tf.layers.conv2d(h_pool1, 64, (5,5), activation = tf.nn.relu, padding='same')\n",
    "h_pool2 = tf.layers.max_pooling2d(h_conv2,(2,2),(2,2),padding='SAME')\n",
    "\n",
    "h_pool2_flat = tf.contrib.layers.flatten(h_pool2)\n",
    "h_fc1 = tf.layers.dense(inputs=h_pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "y_conv = tf.layers.dense(inputs=h_fc1, units=10, activation=None)\n",
    "\n",
    "\n",
    "#cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "#cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv)\n",
    "#train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "### OPTION 1: \n",
    "### Na 500 iter: 0.916567\n",
    "### Na 1000 iter: 0.932292\n",
    "# loss = tf.losses.mean_squared_error(y_, y_conv)\n",
    "# train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "### OPTION 2: \n",
    "### Na 500 iter: 0.960537\n",
    "### Na 1000 iter: 0.970954\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv)\n",
    "# train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "ITERATIONS = 1000\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for iteration in range(ITERATIONS):\n",
    "    batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    train_step.run(session=sess, feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "    if iteration % 100 == 0:\n",
    "        accuracy = get_accuracy(mnist.test, x, y_conv, sess, test_size=100)\n",
    "        print(\"Iteration %d, accuracy: %f\" % (iteration, accuracy))\n",
    "accuracy = get_accuracy(mnist.test, x, y_conv, sess, test_size=10000)\n",
    "print(\"Final performance: accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: visualise the filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filterimgs = list()\n",
    "[n.name for n in tf.get_default_graph().as_graph_def().node]\n",
    "test = tf.get_default_graph().get_tensor_by_name(\"conv2d/kernel:0\")\n",
    "weights = sess.run(test)\n",
    "print(weights.shape)\n",
    "\n",
    "for i in range(32):\n",
    "    careabout = weights[:,:,:,i]\n",
    "\n",
    "    print(careabout.shape)\n",
    "    care = np.reshape(careabout, (FIRST_LAYER_SIZE,FIRST_LAYER_SIZE))\n",
    "    care = care + care.min()\n",
    "    care = care - care.max()\n",
    "    care *= 100\n",
    "    plt.imshow(care, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    filterimgs.append(care)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_sprite_image(images):\n",
    "    \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\"\n",
    "    if isinstance(images, list):\n",
    "        images = np.array(images)\n",
    "    img_h = images.shape[1]\n",
    "    img_w = images.shape[2]\n",
    "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    \n",
    "    \n",
    "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
    "    \n",
    "    for i in range(n_plots):\n",
    "        for j in range(n_plots):\n",
    "            this_filter = i * n_plots + j\n",
    "            if this_filter < images.shape[0]:\n",
    "                this_img = images[this_filter]\n",
    "                spriteimage[i * img_h:(i + 1) * img_h,\n",
    "                  j * img_w:(j + 1) * img_w] = this_img\n",
    "    \n",
    "    return spriteimage\n",
    "\n",
    "imagelist = list()\n",
    "resconv1 = sess.run(h_conv1, feed_dict={x: batch[0], y_: batch[1]})\n",
    "for i in range(32):\n",
    "    interesting = resconv1[1,:,:,i]\n",
    "    inter = np.reshape(interesting, (28,28))\n",
    "    imagelist.append(inter)\n",
    "    plt.imshow(inter,cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = create_sprite_image(imagelist)\n",
    "plt.imsave(\"activations_first_conv_layer.png\",a,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blaatimages = list()\n",
    "for i in range(4):\n",
    "    interesting = resconv1[1,:,:,i]\n",
    "    inter = np.reshape(interesting, (28,28))\n",
    "    blaatimages.append(inter)\n",
    "a = create_sprite_image(blaatimages)\n",
    "plt.imsave(\"somefeatures.png\",a,cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = create_sprite_image(filterimgs)\n",
    "plt.imsave(\"filters_first_conv_layer.png\",a,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "six = np.reshape(batch[0][1], (28,28))\n",
    "plt.imshow(six)\n",
    "plt.show()\n",
    "plt.imshow(np.roll(six,5))\n",
    "plt.show()\n",
    "plt.imshow(np.roll(six,-8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
